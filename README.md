# ğŸ”ª HACKATON FIAP - IA para Devs

Este projeto realiza **detecÃ§Ã£o de objetos cortantes em vÃ­deos** utilizando **YOLOv5**, com possibilidade de treinar um modelo personalizado e testar em arquivos `.mp4` e emitir alertas automÃ¡ticos quando objetos suspeitos forem confirmados por mÃºltiplos frames.

## ğŸ¯ Proposta

âœ… Detectar objetos cortantes (como facas e tesouras) em vÃ­deos utilizando visÃ£o computacional.

âœ… Implementar um sistema inteligente de confirmaÃ§Ã£o baseado em mÃºltiplos frames.

âœ… Enviar alertas automÃ¡ticos quando um objeto for confirmado em cena.

âœ… Permitir treino de um modelo YOLOv5 com dataset personalizado.

âœ… Executar testes com vÃ­deos locais, exibindo ou salvando os resultados.

---

## ğŸ§ª Requisitos

- Python 3.8+
- CUDA (opcional, para uso com GPU)
- DependÃªncias listadas em `requirements.txt`

### ğŸ”§ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/julioleao/hackaton.git
cd hackaton

# Crie e ative um ambiente virtual (opcional)
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate no Windows

# Instale as dependÃªncias
pip install -r requirements.txt
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

As configuraÃ§Ãµes do projeto estÃ£o centralizadas no arquivo `configs.py`, incluindo:

- Caminhos dos vÃ­deos e datasets
- Nome do modelo
- Uso de GPU ou CPU
- Tamanho da imagem
- Se o vÃ­deo serÃ¡ exibido em tempo real (`STREAMING`)

VocÃª pode ajustar os parÃ¢metros para testar com diferentes datasets ou vÃ­deos.

---

## ğŸ‹ï¸ Treinamento

O script `trainer.py` realiza o treinamento usando YOLOv5 e cria automaticamente o `data.yaml` com as classes e caminhos para o dataset.

### â–¶ï¸ Rodar o treinamento

```bash
python trainer.py
```

- O modelo serÃ¡ treinado por 4 Ã©pocas (modificÃ¡vel).
- O checkpoint serÃ¡ salvo em `runs/train/exp/weights/best.pt`.

---

## ğŸ¯ Teste

O script `tester.py` roda o vÃ­deo definido em `configs.py` com o modelo treinado e exibe (ou salva) a detecÃ§Ã£o.

### â–¶ï¸ Rodar o teste

```bash
python tester.py
```

- O vÃ­deo de saÃ­da serÃ¡ salvo como `output.mp4` por padrÃ£o.
- Para visualizaÃ§Ã£o em tempo real, `STREAMING = True` em `configs.py`.

#### Funcionalidades

- A cada frame, a detecÃ§Ã£o Ã© realizada usando YOLOv5.
- Se um objeto Ã© identificado por pelo menos 4 frames consecutivos na mesma regiÃ£o, Ã© confirmado.
- Ao confirmar um novo objeto cortante, uma notificaÃ§Ã£o automÃ¡tica Ã© enviada:
  - Windows: via PowerShell (MessageBox)
  - Linux: via notify-send

#### ParÃ¢metros importantes

- `DIST_THRESHOLD`: distÃ¢ncia mÃ¡xima entre detecÃ§Ãµes para considerÃ¡-las do mesmo objeto.
- `CONFIRM_FRAMES`: nÃºmero mÃ­nimo de frames consecutivos para confirmar o objeto.

---

## ğŸ“ ExplicaÃ§Ã£o dos Arquivos

| Arquivo | FunÃ§Ã£o |
|--- | --- |
| `configs.py` | Define os caminhos, parÃ¢metros de imagem, uso de GPU/CPU, e flags de execuÃ§Ã£o. |
| `trainer.py` | Gera o `data.yaml`e executa o treinamento com o modelo YOLOv5.|
| `tester.py` | Usa o modelo treinado para detectar facas em um vÃ­deo de entrada.|
| `requirements.txt` | Lista as bibliotecas necessÃ¡rias para rodar o projeto.|
| `videos/` | Pasta onde os vÃ­deos de entrada devem ser colocados.|
| `dataset/` | ContÃ©m o dataset usado para o treinamento (ex: imagens, anotaÃ§Ãµes).|

---

## ğŸ“Œ ObservaÃ§Ãµes

- A estrutura do dataset deve seguir o padrÃ£o YOLOv5 (pastas `train/images`, `valid/images`, etc.).
- O cÃ³digo utiliza diretamente os mÃ³dulos do repositÃ³rio oficial do YOLOv5.
- Alertas sÃ£o enviados apenas quando um objeto Ã© `confirmado` (nÃ£o basta aparecer em apenas 1 frame).
- A detecÃ§Ã£o usa limiares de confianÃ§a e IoU configurÃ¡veis no `tester.py`.
