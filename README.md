# üî™ HACKATON FIAP - IA para Devs

Este projeto realiza **detec√ß√£o de objetos cortantes em v√≠deos** utilizando **YOLOv5**, com possibilidade de treinar um modelo personalizado e testar em arquivos `.mp4` e emitir alertas autom√°ticos quando objetos suspeitos forem confirmados por m√∫ltiplos frames.

## Grupo 2

- Julio Cesario de Paiva Le√£o (julio0023@live.com)
- Luis Gustavo Bueno Colombo (luisgustavobuenocolombo@gmail.com)

## URLs do projeto

- [V√≠deo do YouTube](https://www.youtube.com/watch?v=W33Nbd2gj4E)
- [Reposit√≥rio do GitHub](https://github.com/julioleao/hackaton)

## üéØ Proposta

‚úÖ Detectar objetos cortantes (como facas e tesouras) em v√≠deos utilizando vis√£o computacional.

‚úÖ Implementar um sistema inteligente de confirma√ß√£o baseado em m√∫ltiplos frames.

‚úÖ Enviar alertas autom√°ticos quando um objeto for confirmado em cena.

‚úÖ Permitir treino de um modelo YOLOv5 com dataset personalizado.

‚úÖ Executar testes com v√≠deos locais, exibindo ou salvando os resultados.

---

## üß™ Requisitos

- Python 3.8+
- CUDA (opcional, para uso com GPU)
- Depend√™ncias listadas em `requirements.txt`

### üîß Instala√ß√£o

```bash
# Clone o reposit√≥rio
git clone https://github.com/julioleao/hackaton.git
cd hackaton

# Crie e ative um ambiente virtual (opcional)
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate no Windows

# Instale as depend√™ncias
pip install -r requirements.txt
```

---

## ‚öôÔ∏è Configura√ß√£o

As configura√ß√µes do projeto est√£o centralizadas no arquivo `configs.py`, incluindo:

- Caminhos dos v√≠deos e datasets
- Nome do modelo
- Uso de GPU ou CPU
- Tamanho da imagem
- Se o v√≠deo ser√° exibido em tempo real (`STREAMING`)

Voc√™ pode ajustar os par√¢metros para testar com diferentes datasets ou v√≠deos.

---

## üèãÔ∏è Treinamento

O script `trainer.py` realiza o treinamento usando YOLOv5 e cria automaticamente o `data.yaml` com as classes e caminhos para o dataset.

### ‚ñ∂Ô∏è Rodar o treinamento

```bash
python trainer.py
```

- O modelo ser√° treinado por 4 √©pocas (modific√°vel).
- O checkpoint ser√° salvo em `runs/train/exp/weights/best.pt`.

---

## üéØ Teste

O script `tester.py` roda o v√≠deo definido em `configs.py` com o modelo treinado e exibe (ou salva) a detec√ß√£o.

### ‚ñ∂Ô∏è Rodar o teste

```bash
python tester.py
```

- O v√≠deo de sa√≠da ser√° salvo como `output.mp4` por padr√£o.
- Para visualiza√ß√£o em tempo real, `STREAMING = True` em `configs.py`.

#### Funcionalidades

- A cada frame, a detec√ß√£o √© realizada usando YOLOv5.
- Se um objeto √© identificado por pelo menos 4 frames consecutivos na mesma regi√£o, √© confirmado.
- Ao confirmar um novo objeto cortante, uma notifica√ß√£o autom√°tica √© enviada:
  - Windows: via PowerShell (MessageBox)
  - Linux: via notify-send

#### Par√¢metros importantes

- `DIST_THRESHOLD`: dist√¢ncia m√°xima entre detec√ß√µes para consider√°-las do mesmo objeto.
- `CONFIRM_FRAMES`: n√∫mero m√≠nimo de frames consecutivos para confirmar o objeto.

---

## üìù Explica√ß√£o dos Arquivos

| Arquivo | Fun√ß√£o |
|--- | --- |
| `configs.py` | Define os caminhos, par√¢metros de imagem, uso de GPU/CPU, e flags de execu√ß√£o. |
| `trainer.py` | Gera o `data.yaml`e executa o treinamento com o modelo YOLOv5.|
| `tester.py` | Usa o modelo treinado para detectar facas em um v√≠deo de entrada.|
| `requirements.txt` | Lista as bibliotecas necess√°rias para rodar o projeto.|
| `videos/` | Pasta onde os v√≠deos de entrada devem ser colocados.|
| `dataset/` | Cont√©m o dataset usado para o treinamento (ex: imagens, anota√ß√µes).|

---

## üìå Observa√ß√µes

- A estrutura do dataset deve seguir o padr√£o YOLOv5 (pastas `train/images`, `valid/images`, etc.).
- O c√≥digo utiliza diretamente os m√≥dulos do reposit√≥rio oficial do YOLOv5.
- Alertas s√£o enviados apenas quando um objeto √© `confirmado` (n√£o basta aparecer em apenas 1 frame).
- A detec√ß√£o usa limiares de confian√ßa e IoU configur√°veis no `tester.py`.
